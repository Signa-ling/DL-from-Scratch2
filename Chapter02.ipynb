{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コーパスの下準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter02 自然言語と単語の分散表現\n",
    "\n",
    "- そもそも自然言語処理(NLP)とは?\n",
    "  - 人間が普段使う言葉をコンピュータに理解させる為の技術\n",
    "  - 自然言語は同じ意味の文章でも多様な言い回し, 文章に対する曖昧さが存在するといった柔軟性がある\n",
    "    - こうした柔軟性のある言語を機会に理解させるのは難しい → これを解決するのが目標\n",
    "    - ex) 機械翻訳, 検索エンジン, IME, etc...\n",
    "\n",
    "- 本章のテーマ: 単語の意味をコンピュータに理解させる\n",
    "  - 言葉は文字によって構成されるが、言葉の意味は単語によって構成される(i.e. 意味を表す「最小単位」)\n",
    "  - 本章と次章で以下の3つの手法による単語の意味を捉えた表現方法について考える\n",
    "    - シソーラスによる手法(ただしこのノートでは省略する)\n",
    "    - カウントベースの手法\n",
    "    - 推論ベースの手法(次章)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.extmath import randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    # 単語から単語IDへの辞書\n",
    "    word_to_id = {}\n",
    "    \n",
    "    # 単語IDから単語への辞書\n",
    "    id_to_word = {}\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "    \n",
    "    # corpus: 単語IDのリスト\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
      "say\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 処理の確認\n",
    "test_txt = 'You say goodbye and I say hello.'\n",
    "test_corpus, test_word_to_id, test_id_to_word = preprocess(test_txt)\n",
    "print(test_corpus)\n",
    "print(test_word_to_id)\n",
    "print(test_id_to_word)\n",
    "\n",
    "print(test_id_to_word[1])\n",
    "print(test_word_to_id['hello'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 共起行列\n",
    " \n",
    " - 分布仮説に基づいて、特定の単語に着目した際その周囲にどのような単語がどの程度出現するかをカウントし集計する\n",
    "   - この本内ではこれを「カウントベースの手法」とするが、文献によっては「統計的手法」と称される事もある\n",
    " \n",
    "|    |  you  |  say  |  goodbye  |  and  |  i  |  hello  |  .  |\n",
    "| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| you |  0  |  1  |  0  |  0  |  0  |  0  |  0  |\n",
    "\n",
    "\n",
    "- 上記の場合youに着目した際、その周囲にどの単語が何回出るかを示す\n",
    "  - これを各単語について着目し周囲の単語の種類と出現回数を調べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size+1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "            \n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "            \n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "    \n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "[0 1 0 0 0 0 0] [0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 処理の確認\n",
    "vocab_size = len(test_word_to_id)\n",
    "C = create_co_matrix(test_corpus, vocab_size)\n",
    "c0 = C[test_word_to_id['you']]\n",
    "c1 = C[test_word_to_id['i']]\n",
    "print(C)\n",
    "print(c0, c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベクトル間の類似度\n",
    "\n",
    "- 単語のベクトル表現でよく用いられるコサイン類似度(cosine similarity)を利用し単語の類似度を測定する\n",
    "\n",
    "--- \n",
    "\n",
    "#### コサイン類似度の定義\n",
    "\n",
    "$$\n",
    "similarity(x, y) = \\dfrac{x \\cdot y}{\\|x\\| \\|y\\|} = \\dfrac{x_1 y_1 + \\cdots + x_n y_n}{\\sqrt{x_1^2 + \\cdots + x_n^2} \\sqrt{y_1^2 + \\cdots + y_n^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y):\n",
    "    nx = x / np.sqrt(np.sum(x**2))\n",
    "    ny = y / np.sqrt(np.sum(y**2))\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 類似単語のランキング表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    if query not in word_to_id:\n",
    "        print('%s is not found' % query)\n",
    "        return\n",
    "    print('\\n[query]' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "    \n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "        count += 1\n",
    "        if count >= top: return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query]you\n",
      " goodbye: 0.7071067811865475\n",
      " i: 0.7071067811865475\n",
      " hello: 0.7071067811865475\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "most_similar('you', test_word_to_id, test_id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相互情報量\n",
    "\n",
    "- 上記の結果を見ると\"you\"に近い単語は3つある\n",
    "  - そのうちの\"I\"は\"you\"同様に人称代名詞であるため、上記結果でも納得できる\n",
    "  - しかし、\"goodbye\", \"hello\"の値も高いという結果には、人間的な感覚と大きなズレがある\n",
    " \n",
    " - 上記のような問題の原因は特定の単語が高頻度に使用されているほど強い関連性を持ち合わせてしまうこと\n",
    "   - なのでこれを解決するために用いるのが相互情報量(Pointwise Mutmal Information: PMI)\n",
    "\n",
    "---\n",
    "\n",
    "#### PMIの定義\n",
    " \n",
    "$$\n",
    " PMI(x, y) = log_2 \\dfrac{P(x \\cdot y)}{P(x) P(y)} = log_2 \\dfrac{\\dfrac{C(x, y)}{N}}{\\dfrac{C(x)}{N} \\dfrac{C(y)}{N}} = log_2 \\dfrac{C(x, y) \\cdot N}{C(x) C(y)}\n",
    "$$\n",
    " \n",
    "$P(x), P(y)$: xが起こる確率, yが起こる確率\n",
    "\n",
    "$P(x \\cdot y)$: xとyが同時に起こる確率\n",
    "\n",
    "$C(x), C(y)$: xの出現回数, yの出現回数\n",
    "\n",
    "$N$: コーパスに含まれる単語数\n",
    "\n",
    "---\n",
    "\n",
    "- 上記のままでは$log_2 0 = - \\infty$となる\n",
    "  - 実践上では以下に示す正の相互情報量(Positive PMI: PPMI)を用いることでPMIがマイナスの際にそれを0として扱えるようにする\n",
    "\n",
    "$$\n",
    "PPMI(x, y) = max(0, PMI(x, y))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小さい数epsを加えることでlog2(0)になるのを防ぐ\n",
    "def ppmi(C, verbose=False, eps=1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j] * S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "            \n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0:\n",
    "                    print('%.lf%% done' %(100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "# ppmiの確認\n",
    "W = ppmi(C)\n",
    "\n",
    "# 有効桁3桁で表示\n",
    "np.set_printoptions(precision=3)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次元削減\n",
    "\n",
    "- ベクトルの中から重要な情報をできるだけ残した上で次元を削減する手法\n",
    "- 削減手法はいくつか存在するがここでは特異値分解(Singular Value Decomposition: SVD)を使用する\n",
    "  - SVD: 任意の行列を3つの行列の積へと分解する\n",
    "  - 行列サイズをNとした時、SVDの計算量は$O(N^3)$となる為、現実にはTruncated SVDなどの高速な手法が用いられる\n",
    "  \n",
    "---\n",
    "\n",
    "#### SVDの定義\n",
    "\n",
    "$$\n",
    "X = USV^T\n",
    "$$\n",
    "\n",
    "$X$: 任意の行列\n",
    "\n",
    "$U, V$: 直交行列\n",
    "\n",
    "$S$: 対角行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共起行列: [0 1 0 0 0 0 0]\n",
      "PPMI行列: [0.    1.807 0.    0.    0.    0.    0.   ]\n",
      "SVD: [ 0.000e+00  3.409e-01 -1.205e-01 -3.886e-16 -1.110e-16 -9.323e-01\n",
      " -2.426e-17]\n"
     ]
    }
   ],
   "source": [
    "U, S, V = np.linalg.svd(W)\n",
    "print('共起行列: {}'.format(C[0]))\n",
    "print('PPMI行列: {}'.format(W[0]))\n",
    "print('SVD: {}'.format(U[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for word, word_id in test_word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "\n",
    "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
    "\n",
    "# 本とは軸などが異なるが示してる部分は同等である\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTBデータセット\n",
    "\n",
    "- Penn TreeBank(PTB)コーパスの事\n",
    "  - 元となるPTBの文章に対しいくつかの前処理が施されている\n",
    "  \n",
    "- PTBデータセットのダウンロードについては[deep-learning-from-scratch-2のリポジトリ](https://github.com/oreilly-japan/deep-learning-from-scratch-2)にある/dataset/ptb.pyを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size: 929589\n",
      "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id['car']: 3856\n",
      "word_to_id['happy']: 4428\n",
      "word_to_id['lexus']: 7426\n"
     ]
    }
   ],
   "source": [
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "print('corpus size:', len(corpus))\n",
    "print('corpus[:30]:', corpus[:30])\n",
    "print()\n",
    "print('id_to_word[0]:', id_to_word[0])\n",
    "print('id_to_word[1]:', id_to_word[1])\n",
    "print('id_to_word[2]:', id_to_word[2])\n",
    "print()\n",
    "print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting co-occurrence ...\n",
      "calculating PPMI ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\scripts\\python\\dl-from-scratch2\\dl-from-scratch2\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in long_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "e:\\scripts\\python\\dl-from-scratch2\\dl-from-scratch2\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in log2\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1% done\n",
      "2% done\n",
      "3% done\n",
      "4% done\n",
      "5% done\n",
      "6% done\n",
      "7% done\n",
      "8% done\n",
      "9% done\n",
      "10% done\n",
      "11% done\n",
      "12% done\n",
      "13% done\n",
      "14% done\n",
      "15% done\n",
      "16% done\n",
      "17% done\n",
      "18% done\n",
      "19% done\n",
      "20% done\n",
      "21% done\n",
      "22% done\n",
      "23% done\n",
      "24% done\n",
      "25% done\n",
      "26% done\n",
      "27% done\n",
      "28% done\n",
      "29% done\n",
      "30% done\n",
      "31% done\n",
      "32% done\n",
      "33% done\n",
      "34% done\n",
      "35% done\n",
      "36% done\n",
      "37% done\n",
      "38% done\n",
      "39% done\n",
      "40% done\n",
      "41% done\n",
      "42% done\n",
      "43% done\n",
      "44% done\n",
      "45% done\n",
      "46% done\n",
      "47% done\n",
      "48% done\n",
      "49% done\n",
      "50% done\n",
      "51% done\n",
      "52% done\n",
      "53% done\n",
      "54% done\n",
      "55% done\n",
      "56% done\n",
      "57% done\n",
      "58% done\n",
      "59% done\n",
      "60% done\n",
      "61% done\n",
      "62% done\n",
      "63% done\n",
      "64% done\n",
      "65% done\n",
      "66% done\n",
      "67% done\n",
      "68% done\n",
      "69% done\n",
      "70% done\n",
      "71% done\n",
      "72% done\n",
      "73% done\n",
      "74% done\n",
      "75% done\n",
      "76% done\n",
      "77% done\n",
      "78% done\n",
      "79% done\n",
      "80% done\n",
      "81% done\n",
      "82% done\n",
      "83% done\n",
      "84% done\n",
      "85% done\n",
      "86% done\n",
      "87% done\n",
      "88% done\n",
      "89% done\n",
      "90% done\n",
      "91% done\n",
      "92% done\n",
      "93% done\n",
      "94% done\n",
      "95% done\n",
      "96% done\n",
      "97% done\n",
      "98% done\n",
      "99% done\n",
      "100% done\n",
      "calculating SVD ...\n",
      "\n",
      "[query]you\n",
      " i: 0.687149703502655\n",
      " we: 0.6506008505821228\n",
      " 'll: 0.5494743585586548\n",
      " someone: 0.5454580783843994\n",
      " anybody: 0.5311956405639648\n",
      "\n",
      "[query]year\n",
      " month: 0.6729631423950195\n",
      " last: 0.6361977458000183\n",
      " earlier: 0.6215190887451172\n",
      " quarter: 0.6139706373214722\n",
      " next: 0.6079318523406982\n",
      "\n",
      "[query]car\n",
      " auto: 0.6543340682983398\n",
      " luxury: 0.6072489023208618\n",
      " cars: 0.5442463755607605\n",
      " corsica: 0.497117817401886\n",
      " vehicle: 0.49192509055137634\n",
      "\n",
      "[query]toyota\n",
      " motor: 0.7317686676979065\n",
      " honda: 0.6628273129463196\n",
      " motors: 0.6482638716697693\n",
      " nissan: 0.6228052377700806\n",
      " lexus: 0.6087705492973328\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "vocab_size = len(word_to_id)\n",
    "print('counting co-occurrence ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('calculating PPMI ...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('calculating SVD ...')\n",
    "try:\n",
    "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5,\n",
    "                             random_state=None)\n",
    "except ImportError:\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter06 ゲート付きRNN\n",
    "\n",
    "---\n",
    "\n",
    "## 前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "from common.base_model import BaseModel\n",
    "from common.functions import sigmoid\n",
    "from common.time_layers import *\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNの問題点\n",
    "\n",
    "- RNNは時系列データの長期の依存関係を学習することが苦手\n",
    "  - BPTT(Backpropagation Through Time)が勾配消失もしくは勾配爆発を起こすため\n",
    "    - 勾配消失の原因: $y = \\tanh(x)$の微分$\\frac{\\partial y}{\\partial x} = 1 - y^2$となり, 時間を経る度に1より小さい数が乗算される\n",
    "    - 勾配爆発の原因: MatMulを通るたびに重みをT回乗算するために起こる\n",
    "\n",
    "- 勾配爆発は勾配クリッピングによって対策が出来る(以下は擬似コード)\n",
    "  - $\\|\\hat{g}\\|$が$threshold$を超えた場合に勾配の修正を行うというもの\n",
    "$$\n",
    "\\mathrm{if} \\quad \\|\\hat{g}\\| \\geq threshold: \\\\\n",
    "\\hat{g} = \\dfrac{threshold}{\\|\\hat{g}\\|}\\hat{g}\n",
    "$$\n",
    "\n",
    "- $threshold$: 閾値\n",
    "$\\hat{g}$: NNで使用される全てのパラメータの勾配を一つにまとめたもの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配消失とLSTM\n",
    "\n",
    "- 勾配消失問題を解決するにはアーキテクチャを根本から変える必要がある\n",
    "  - その1つがゲート付きRNN\n",
    "    - 代表的手法にLSTMとGRUがあるが, 本章ではLSTMに焦点を当てる\n",
    "    \n",
    "- RNNとLSTMの違いとしてLSTMには記憶セルが存在する\n",
    "  - この記憶セルはLSTMレイヤ内で完結するため他のレイヤへ出力しない\n",
    "  - 現在の記憶セル$c_t$は3つの入力($c_{t-1}, h_{t_1}, x_t$)から後述していく計算によって求められる\n",
    "  - 更新された$c_t$を使用して隠れ状態$h_t$が計算される\n",
    "    - この計算は$h_t = \\tanh(c_t)$によって$c_t$の各要素に対し$\\tanh$関数を適用する\n",
    "\n",
    "- LSTMにはゲートという機能がある\n",
    "  - データの流れをコントロールする\n",
    "  - 「output」「forget」「input」の3種類のゲートが存在する\n",
    "\n",
    "---\n",
    "\n",
    "- 入力データに対し, ゲートは以下の順で動作を行い, $h_t$を出力する\n",
    "  - forgetゲート: 記憶セル$c_{t-1}$に対し何を忘れるかを指示するゲート\n",
    "    - このままでは忘れただけで新しい情報$\\mathrm{g}$を記憶セルに追加する\n",
    "  - inputゲート: $\\mathrm{g}$の各要素が新たに追加する情報としてどれだけ価値があるかを判断する(追加情報の取捨選択)\n",
    "  - outputゲート: $\\tanh(c_t)$の各要素に対し, 「それらが次時刻の隠れ状態としてどれだけ重要か」を調整するゲート\n",
    "\n",
    "- 上記の4工程を式に表すと以下となる\n",
    "  - forgetゲート: $\\mathrm{f} = \\sigma(x_t W_x^{(\\mathrm{f})} + h_{t-1}W_h^{(\\mathrm{f})} + b^{(\\mathrm{f})})$\n",
    "  - 情報の追加: $\\mathrm{g} = \\tanh(x_t W_x^{(\\mathbf{g})} + h_{t-1}W_h^{(\\mathbf{g})} + b^{(\\mathrm{g})})$\n",
    "  - inputゲート: $\\mathrm{i} = \\sigma(x_t W_x^{(\\mathrm{i})} + h_{t-1}W_h^{(\\mathrm{i})} + b^{(\\mathrm{i})})$\n",
    "  - outputゲート: $\\mathrm{o} = \\sigma(x_t W_x^{(\\mathrm{o})} + h_{t-1}W_h^{(\\mathrm{o})} + b^{(\\mathrm{o})})$\n",
    "  \n",
    "- forgetゲート, 追加情報, inputゲートの3つの出力と前の時刻の記憶セル$c_{t-1}$によって現時刻の記憶セル$c_t$を求められる\n",
    "  - $c_t = \\mathrm{f} \\odot c_{t-1} + \\mathrm{g} \\odot \\mathrm{i}$\n",
    "- outputゲートの出力$\\mathrm{o}$に対し$\\tanh(c_t)$とのアダマール積を計算し$h_t$を求める事ができる\n",
    "  - $h_t = \\mathrm{o} \\odot \\tanh(c_t)$\n",
    "- RNNの逆伝播では同じ重みと行列を使用した「行列の積」を繰り返し行っていたが, LSTMの逆伝播では「要素ごとの積」を毎時刻, 異なるゲート値によって行うため勾配消失が起こりにくい\n",
    "\n",
    "---\n",
    "\n",
    "## LSTMの実装\n",
    "\n",
    "- forget ~ outputまでの4つの式はいずれも関数内で$xW_x+hW_h+b$の形状をとっている為, 以下のような計算を行ったほうが計算を高速化することができる\n",
    "$$\n",
    "x_t[W_x^{(\\mathrm{f})} \\quad W_x^{(\\mathrm{g})} \\quad W_x^{(\\mathrm{i})} \\quad W_x^{(\\mathrm{o})}] + h_{t-1}[W_h^{(\\mathrm{f})} \\quad W_h^{(\\mathrm{g})} \\quad W_h^{(\\mathrm{i})} \\quad W_h^{(\\mathrm{o})}] + [b^{(\\mathrm{f})} \\quad b^{(\\mathrm{g})} \\quad b^{(\\mathrm{i})} \\quad b^{(\\mathrm{o})}] \\\\\n",
    "= x_tW_x + h_{t-1}W_h + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        # Wx, Wh, bには4つ分の重み, バイアスがまとめられている\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "        \n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H: 3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "    \n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "        \n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "        dc_prev = ds * f\n",
    "        \n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "        \n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= g * (1 - g ** 2)\n",
    "        \n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "        \n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TimeLSTMの実装\n",
    "\n",
    "- T個分の時系列データをまとめて処理するレイヤ\n",
    "  - T個のLSTMレイヤによって構成される\n",
    "  \n",
    " - Truncated BPTTは逆伝播のつながりを適当な長さで断ち切り, 順伝播の流れは維持する必要がある\n",
    "   - なので隠れ状態と記憶セルをメンバ変数に保持させるようにすることで次のforward()が呼ばれた際に, 前時刻の隠れ状態と記憶セルから開始することができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## LSTMを使った言語モデル\n",
    "\n",
    "- 前章のTimeRNNレイヤの場所にTimeLSTMレイヤを使用する\n",
    "  - ネットワーク構成に関してはChpter05.ipynbを参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnnlm:\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4*H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4*H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "        \n",
    "        # 全ての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    # 7章で使用するメソッド\n",
    "    # 本章では使用しないため不要だが一応掲載\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "    \n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n",
    "    \n",
    "    def save_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(self.params, f)\n",
    "    \n",
    "    def load_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.params = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### PTBデータセットの学習\n",
    "\n",
    "- 前章と異なりPTBデータセットの訓練データすべてを使って学習をする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 1327 | time 0[s] | perplexity 10000.57\n",
      "| epoch 1 |  iter 21 / 1327 | time 7[s] | perplexity 2333.09\n",
      "| epoch 1 |  iter 41 / 1327 | time 14[s] | perplexity 1302.65\n",
      "| epoch 1 |  iter 61 / 1327 | time 21[s] | perplexity 1099.69\n",
      "| epoch 1 |  iter 81 / 1327 | time 28[s] | perplexity 958.64\n",
      "| epoch 1 |  iter 101 / 1327 | time 35[s] | perplexity 837.38\n",
      "| epoch 1 |  iter 121 / 1327 | time 42[s] | perplexity 833.66\n",
      "| epoch 1 |  iter 141 / 1327 | time 49[s] | perplexity 789.58\n",
      "| epoch 1 |  iter 161 / 1327 | time 56[s] | perplexity 707.46\n",
      "| epoch 1 |  iter 181 / 1327 | time 63[s] | perplexity 709.23\n",
      "| epoch 1 |  iter 201 / 1327 | time 70[s] | perplexity 625.92\n",
      "| epoch 1 |  iter 221 / 1327 | time 77[s] | perplexity 606.73\n",
      "| epoch 1 |  iter 241 / 1327 | time 84[s] | perplexity 544.74\n",
      "| epoch 1 |  iter 261 / 1327 | time 91[s] | perplexity 577.84\n",
      "| epoch 1 |  iter 281 / 1327 | time 98[s] | perplexity 547.05\n",
      "| epoch 1 |  iter 301 / 1327 | time 105[s] | perplexity 487.14\n",
      "| epoch 1 |  iter 321 / 1327 | time 112[s] | perplexity 441.88\n",
      "| epoch 1 |  iter 341 / 1327 | time 119[s] | perplexity 501.55\n",
      "| epoch 1 |  iter 361 / 1327 | time 126[s] | perplexity 509.55\n",
      "| epoch 1 |  iter 381 / 1327 | time 133[s] | perplexity 440.86\n",
      "| epoch 1 |  iter 401 / 1327 | time 140[s] | perplexity 454.08\n",
      "| epoch 1 |  iter 421 / 1327 | time 147[s] | perplexity 443.86\n",
      "| epoch 1 |  iter 441 / 1327 | time 154[s] | perplexity 422.37\n",
      "| epoch 1 |  iter 461 / 1327 | time 161[s] | perplexity 412.21\n",
      "| epoch 1 |  iter 481 / 1327 | time 168[s] | perplexity 385.57\n",
      "| epoch 1 |  iter 501 / 1327 | time 175[s] | perplexity 408.27\n",
      "| epoch 1 |  iter 521 / 1327 | time 182[s] | perplexity 374.08\n",
      "| epoch 1 |  iter 541 / 1327 | time 189[s] | perplexity 394.89\n",
      "| epoch 1 |  iter 561 / 1327 | time 196[s] | perplexity 360.84\n",
      "| epoch 1 |  iter 581 / 1327 | time 203[s] | perplexity 325.16\n",
      "| epoch 1 |  iter 601 / 1327 | time 210[s] | perplexity 423.43\n",
      "| epoch 1 |  iter 621 / 1327 | time 217[s] | perplexity 397.53\n",
      "| epoch 1 |  iter 641 / 1327 | time 224[s] | perplexity 361.68\n",
      "| epoch 1 |  iter 661 / 1327 | time 231[s] | perplexity 343.14\n",
      "| epoch 1 |  iter 681 / 1327 | time 238[s] | perplexity 299.38\n",
      "| epoch 1 |  iter 701 / 1327 | time 245[s] | perplexity 317.48\n",
      "| epoch 1 |  iter 721 / 1327 | time 252[s] | perplexity 324.13\n",
      "| epoch 1 |  iter 741 / 1327 | time 259[s] | perplexity 285.84\n",
      "| epoch 1 |  iter 761 / 1327 | time 266[s] | perplexity 302.62\n",
      "| epoch 1 |  iter 781 / 1327 | time 273[s] | perplexity 278.65\n",
      "| epoch 1 |  iter 801 / 1327 | time 280[s] | perplexity 303.87\n",
      "| epoch 1 |  iter 821 / 1327 | time 287[s] | perplexity 281.54\n",
      "| epoch 1 |  iter 841 / 1327 | time 294[s] | perplexity 287.40\n",
      "| epoch 1 |  iter 861 / 1327 | time 301[s] | perplexity 282.69\n",
      "| epoch 1 |  iter 881 / 1327 | time 308[s] | perplexity 265.16\n",
      "| epoch 1 |  iter 901 / 1327 | time 315[s] | perplexity 314.69\n",
      "| epoch 1 |  iter 921 / 1327 | time 322[s] | perplexity 292.01\n",
      "| epoch 1 |  iter 941 / 1327 | time 329[s] | perplexity 295.28\n",
      "| epoch 1 |  iter 961 / 1327 | time 336[s] | perplexity 310.34\n",
      "| epoch 1 |  iter 981 / 1327 | time 343[s] | perplexity 290.90\n",
      "| epoch 1 |  iter 1001 / 1327 | time 350[s] | perplexity 248.32\n",
      "| epoch 1 |  iter 1021 / 1327 | time 357[s] | perplexity 285.26\n",
      "| epoch 1 |  iter 1041 / 1327 | time 364[s] | perplexity 266.89\n",
      "| epoch 1 |  iter 1061 / 1327 | time 371[s] | perplexity 256.70\n",
      "| epoch 1 |  iter 1081 / 1327 | time 378[s] | perplexity 222.51\n",
      "| epoch 1 |  iter 1101 / 1327 | time 385[s] | perplexity 255.74\n",
      "| epoch 1 |  iter 1121 / 1327 | time 392[s] | perplexity 297.81\n",
      "| epoch 1 |  iter 1141 / 1327 | time 399[s] | perplexity 268.28\n",
      "| epoch 1 |  iter 1161 / 1327 | time 406[s] | perplexity 260.39\n",
      "| epoch 1 |  iter 1181 / 1327 | time 413[s] | perplexity 242.31\n",
      "| epoch 1 |  iter 1201 / 1327 | time 420[s] | perplexity 208.44\n",
      "| epoch 1 |  iter 1221 / 1327 | time 427[s] | perplexity 207.88\n",
      "| epoch 1 |  iter 1241 / 1327 | time 434[s] | perplexity 248.05\n",
      "| epoch 1 |  iter 1261 / 1327 | time 441[s] | perplexity 224.98\n",
      "| epoch 1 |  iter 1281 / 1327 | time 448[s] | perplexity 233.89\n",
      "| epoch 1 |  iter 1301 / 1327 | time 455[s] | perplexity 290.64\n",
      "| epoch 1 |  iter 1321 / 1327 | time 462[s] | perplexity 271.11\n",
      "| epoch 2 |  iter 1 / 1327 | time 465[s] | perplexity 282.88\n",
      "| epoch 2 |  iter 21 / 1327 | time 472[s] | perplexity 272.51\n",
      "| epoch 2 |  iter 41 / 1327 | time 479[s] | perplexity 250.52\n",
      "| epoch 2 |  iter 61 / 1327 | time 486[s] | perplexity 230.06\n",
      "| epoch 2 |  iter 81 / 1327 | time 493[s] | perplexity 211.60\n",
      "| epoch 2 |  iter 101 / 1327 | time 500[s] | perplexity 201.12\n",
      "| epoch 2 |  iter 121 / 1327 | time 507[s] | perplexity 215.04\n",
      "| epoch 2 |  iter 141 / 1327 | time 514[s] | perplexity 239.11\n",
      "| epoch 2 |  iter 161 / 1327 | time 521[s] | perplexity 252.28\n",
      "| epoch 2 |  iter 181 / 1327 | time 528[s] | perplexity 263.34\n",
      "| epoch 2 |  iter 201 / 1327 | time 535[s] | perplexity 244.42\n",
      "| epoch 2 |  iter 221 / 1327 | time 542[s] | perplexity 245.32\n",
      "| epoch 2 |  iter 241 / 1327 | time 549[s] | perplexity 229.38\n",
      "| epoch 2 |  iter 261 / 1327 | time 556[s] | perplexity 244.61\n",
      "| epoch 2 |  iter 281 / 1327 | time 563[s] | perplexity 249.45\n",
      "| epoch 2 |  iter 301 / 1327 | time 570[s] | perplexity 222.58\n",
      "| epoch 2 |  iter 321 / 1327 | time 577[s] | perplexity 192.45\n",
      "| epoch 2 |  iter 341 / 1327 | time 584[s] | perplexity 233.84\n",
      "| epoch 2 |  iter 361 / 1327 | time 591[s] | perplexity 265.78\n",
      "| epoch 2 |  iter 381 / 1327 | time 598[s] | perplexity 210.17\n",
      "| epoch 2 |  iter 401 / 1327 | time 605[s] | perplexity 226.63\n",
      "| epoch 2 |  iter 421 / 1327 | time 612[s] | perplexity 215.24\n",
      "| epoch 2 |  iter 441 / 1327 | time 619[s] | perplexity 223.08\n",
      "| epoch 2 |  iter 461 / 1327 | time 626[s] | perplexity 215.96\n",
      "| epoch 2 |  iter 481 / 1327 | time 633[s] | perplexity 214.11\n",
      "| epoch 2 |  iter 501 / 1327 | time 640[s] | perplexity 227.73\n",
      "| epoch 2 |  iter 521 / 1327 | time 647[s] | perplexity 231.83\n",
      "| epoch 2 |  iter 541 / 1327 | time 654[s] | perplexity 234.98\n",
      "| epoch 2 |  iter 561 / 1327 | time 661[s] | perplexity 212.29\n",
      "| epoch 2 |  iter 581 / 1327 | time 668[s] | perplexity 191.11\n",
      "| epoch 2 |  iter 601 / 1327 | time 675[s] | perplexity 259.94\n",
      "| epoch 2 |  iter 621 / 1327 | time 682[s] | perplexity 242.82\n",
      "| epoch 2 |  iter 641 / 1327 | time 689[s] | perplexity 224.62\n",
      "| epoch 2 |  iter 661 / 1327 | time 696[s] | perplexity 210.47\n",
      "| epoch 2 |  iter 681 / 1327 | time 703[s] | perplexity 176.49\n",
      "| epoch 2 |  iter 701 / 1327 | time 710[s] | perplexity 204.28\n",
      "| epoch 2 |  iter 721 / 1327 | time 717[s] | perplexity 217.40\n",
      "| epoch 2 |  iter 741 / 1327 | time 724[s] | perplexity 179.66\n",
      "| epoch 2 |  iter 761 / 1327 | time 731[s] | perplexity 181.35\n",
      "| epoch 2 |  iter 781 / 1327 | time 738[s] | perplexity 183.43\n",
      "| epoch 2 |  iter 801 / 1327 | time 745[s] | perplexity 200.36\n",
      "| epoch 2 |  iter 821 / 1327 | time 752[s] | perplexity 191.18\n",
      "| epoch 2 |  iter 841 / 1327 | time 759[s] | perplexity 192.50\n",
      "| epoch 2 |  iter 861 / 1327 | time 766[s] | perplexity 195.33\n",
      "| epoch 2 |  iter 881 / 1327 | time 773[s] | perplexity 177.93\n",
      "| epoch 2 |  iter 901 / 1327 | time 780[s] | perplexity 222.08\n",
      "| epoch 2 |  iter 921 / 1327 | time 787[s] | perplexity 198.48\n",
      "| epoch 2 |  iter 941 / 1327 | time 794[s] | perplexity 204.45\n",
      "| epoch 2 |  iter 961 / 1327 | time 801[s] | perplexity 221.99\n",
      "| epoch 2 |  iter 981 / 1327 | time 808[s] | perplexity 208.53\n",
      "| epoch 2 |  iter 1001 / 1327 | time 815[s] | perplexity 177.69\n",
      "| epoch 2 |  iter 1021 / 1327 | time 822[s] | perplexity 206.78\n",
      "| epoch 2 |  iter 1041 / 1327 | time 829[s] | perplexity 190.93\n",
      "| epoch 2 |  iter 1061 / 1327 | time 836[s] | perplexity 176.08\n",
      "| epoch 2 |  iter 1081 / 1327 | time 843[s] | perplexity 155.36\n",
      "| epoch 2 |  iter 1101 / 1327 | time 850[s] | perplexity 169.45\n",
      "| epoch 2 |  iter 1121 / 1327 | time 857[s] | perplexity 209.08\n",
      "| epoch 2 |  iter 1141 / 1327 | time 864[s] | perplexity 191.02\n",
      "| epoch 2 |  iter 1161 / 1327 | time 871[s] | perplexity 185.56\n",
      "| epoch 2 |  iter 1181 / 1327 | time 879[s] | perplexity 177.29\n",
      "| epoch 2 |  iter 1201 / 1327 | time 886[s] | perplexity 150.92\n",
      "| epoch 2 |  iter 1221 / 1327 | time 893[s] | perplexity 145.97\n",
      "| epoch 2 |  iter 1241 / 1327 | time 900[s] | perplexity 180.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 2 |  iter 1261 / 1327 | time 907[s] | perplexity 167.83\n",
      "| epoch 2 |  iter 1281 / 1327 | time 914[s] | perplexity 168.60\n",
      "| epoch 2 |  iter 1301 / 1327 | time 921[s] | perplexity 210.62\n",
      "| epoch 2 |  iter 1321 / 1327 | time 929[s] | perplexity 202.01\n",
      "| epoch 3 |  iter 1 / 1327 | time 931[s] | perplexity 214.90\n",
      "| epoch 3 |  iter 21 / 1327 | time 938[s] | perplexity 200.21\n",
      "| epoch 3 |  iter 41 / 1327 | time 945[s] | perplexity 188.94\n",
      "| epoch 3 |  iter 61 / 1327 | time 952[s] | perplexity 174.09\n",
      "| epoch 3 |  iter 81 / 1327 | time 959[s] | perplexity 159.34\n",
      "| epoch 3 |  iter 101 / 1327 | time 966[s] | perplexity 146.68\n",
      "| epoch 3 |  iter 121 / 1327 | time 973[s] | perplexity 160.15\n",
      "| epoch 3 |  iter 141 / 1327 | time 980[s] | perplexity 171.15\n",
      "| epoch 3 |  iter 161 / 1327 | time 987[s] | perplexity 190.90\n",
      "| epoch 3 |  iter 181 / 1327 | time 995[s] | perplexity 201.86\n",
      "| epoch 3 |  iter 201 / 1327 | time 1002[s] | perplexity 190.68\n",
      "| epoch 3 |  iter 221 / 1327 | time 1009[s] | perplexity 192.67\n",
      "| epoch 3 |  iter 241 / 1327 | time 1016[s] | perplexity 180.14\n",
      "| epoch 3 |  iter 261 / 1327 | time 1023[s] | perplexity 186.21\n",
      "| epoch 3 |  iter 281 / 1327 | time 1030[s] | perplexity 189.92\n",
      "| epoch 3 |  iter 301 / 1327 | time 1037[s] | perplexity 169.72\n",
      "| epoch 3 |  iter 321 / 1327 | time 1044[s] | perplexity 143.32\n",
      "| epoch 3 |  iter 341 / 1327 | time 1051[s] | perplexity 170.64\n",
      "| epoch 3 |  iter 361 / 1327 | time 1058[s] | perplexity 209.17\n",
      "| epoch 3 |  iter 381 / 1327 | time 1065[s] | perplexity 157.01\n",
      "| epoch 3 |  iter 401 / 1327 | time 1072[s] | perplexity 175.54\n",
      "| epoch 3 |  iter 421 / 1327 | time 1079[s] | perplexity 162.32\n",
      "| epoch 3 |  iter 441 / 1327 | time 1086[s] | perplexity 171.34\n",
      "| epoch 3 |  iter 461 / 1327 | time 1093[s] | perplexity 164.07\n",
      "| epoch 3 |  iter 481 / 1327 | time 1101[s] | perplexity 164.01\n",
      "| epoch 3 |  iter 501 / 1327 | time 1108[s] | perplexity 177.49\n",
      "| epoch 3 |  iter 521 / 1327 | time 1115[s] | perplexity 185.38\n",
      "| epoch 3 |  iter 541 / 1327 | time 1122[s] | perplexity 183.78\n",
      "| epoch 3 |  iter 561 / 1327 | time 1129[s] | perplexity 164.31\n",
      "| epoch 3 |  iter 581 / 1327 | time 1136[s] | perplexity 147.46\n",
      "| epoch 3 |  iter 601 / 1327 | time 1143[s] | perplexity 204.16\n",
      "| epoch 3 |  iter 621 / 1327 | time 1150[s] | perplexity 195.47\n",
      "| epoch 3 |  iter 641 / 1327 | time 1158[s] | perplexity 182.43\n",
      "| epoch 3 |  iter 661 / 1327 | time 1165[s] | perplexity 168.55\n",
      "| epoch 3 |  iter 681 / 1327 | time 1173[s] | perplexity 137.12\n",
      "| epoch 3 |  iter 701 / 1327 | time 1180[s] | perplexity 161.45\n",
      "| epoch 3 |  iter 721 / 1327 | time 1187[s] | perplexity 172.39\n",
      "| epoch 3 |  iter 741 / 1327 | time 1194[s] | perplexity 145.98\n",
      "| epoch 3 |  iter 761 / 1327 | time 1201[s] | perplexity 147.62\n",
      "| epoch 3 |  iter 781 / 1327 | time 1208[s] | perplexity 141.64\n",
      "| epoch 3 |  iter 801 / 1327 | time 1215[s] | perplexity 158.72\n",
      "| epoch 3 |  iter 821 / 1327 | time 1222[s] | perplexity 152.72\n",
      "| epoch 3 |  iter 841 / 1327 | time 1229[s] | perplexity 153.83\n",
      "| epoch 3 |  iter 861 / 1327 | time 1236[s] | perplexity 161.12\n",
      "| epoch 3 |  iter 881 / 1327 | time 1243[s] | perplexity 144.07\n",
      "| epoch 3 |  iter 901 / 1327 | time 1251[s] | perplexity 179.88\n",
      "| epoch 3 |  iter 921 / 1327 | time 1258[s] | perplexity 160.79\n",
      "| epoch 3 |  iter 941 / 1327 | time 1265[s] | perplexity 166.79\n",
      "| epoch 3 |  iter 961 / 1327 | time 1272[s] | perplexity 176.85\n",
      "| epoch 3 |  iter 981 / 1327 | time 1279[s] | perplexity 164.33\n",
      "| epoch 3 |  iter 1001 / 1327 | time 1286[s] | perplexity 144.16\n",
      "| epoch 3 |  iter 1021 / 1327 | time 1294[s] | perplexity 166.69\n",
      "| epoch 3 |  iter 1041 / 1327 | time 1301[s] | perplexity 160.83\n",
      "| epoch 3 |  iter 1061 / 1327 | time 1308[s] | perplexity 141.36\n",
      "| epoch 3 |  iter 1081 / 1327 | time 1316[s] | perplexity 122.84\n",
      "| epoch 3 |  iter 1101 / 1327 | time 1323[s] | perplexity 136.26\n",
      "| epoch 3 |  iter 1121 / 1327 | time 1330[s] | perplexity 167.00\n",
      "| epoch 3 |  iter 1141 / 1327 | time 1337[s] | perplexity 153.31\n",
      "| epoch 3 |  iter 1161 / 1327 | time 1344[s] | perplexity 151.66\n",
      "| epoch 3 |  iter 1181 / 1327 | time 1351[s] | perplexity 145.64\n",
      "| epoch 3 |  iter 1201 / 1327 | time 1359[s] | perplexity 127.19\n",
      "| epoch 3 |  iter 1221 / 1327 | time 1366[s] | perplexity 118.48\n",
      "| epoch 3 |  iter 1241 / 1327 | time 1373[s] | perplexity 146.53\n",
      "| epoch 3 |  iter 1261 / 1327 | time 1380[s] | perplexity 142.18\n",
      "| epoch 3 |  iter 1281 / 1327 | time 1387[s] | perplexity 138.24\n",
      "| epoch 3 |  iter 1301 / 1327 | time 1395[s] | perplexity 177.27\n",
      "| epoch 3 |  iter 1321 / 1327 | time 1402[s] | perplexity 167.73\n",
      "| epoch 4 |  iter 1 / 1327 | time 1404[s] | perplexity 179.00\n",
      "| epoch 4 |  iter 21 / 1327 | time 1411[s] | perplexity 170.03\n",
      "| epoch 4 |  iter 41 / 1327 | time 1419[s] | perplexity 149.68\n",
      "| epoch 4 |  iter 61 / 1327 | time 1426[s] | perplexity 147.44\n",
      "| epoch 4 |  iter 81 / 1327 | time 1433[s] | perplexity 132.08\n",
      "| epoch 4 |  iter 101 / 1327 | time 1440[s] | perplexity 122.39\n",
      "| epoch 4 |  iter 121 / 1327 | time 1447[s] | perplexity 132.04\n",
      "| epoch 4 |  iter 141 / 1327 | time 1454[s] | perplexity 138.98\n",
      "| epoch 4 |  iter 161 / 1327 | time 1461[s] | perplexity 157.28\n",
      "| epoch 4 |  iter 181 / 1327 | time 1469[s] | perplexity 173.11\n",
      "| epoch 4 |  iter 201 / 1327 | time 1476[s] | perplexity 160.25\n",
      "| epoch 4 |  iter 221 / 1327 | time 1483[s] | perplexity 161.33\n",
      "| epoch 4 |  iter 241 / 1327 | time 1490[s] | perplexity 154.25\n",
      "| epoch 4 |  iter 261 / 1327 | time 1497[s] | perplexity 156.31\n",
      "| epoch 4 |  iter 281 / 1327 | time 1504[s] | perplexity 165.77\n",
      "| epoch 4 |  iter 301 / 1327 | time 1512[s] | perplexity 146.13\n",
      "| epoch 4 |  iter 321 / 1327 | time 1519[s] | perplexity 119.84\n",
      "| epoch 4 |  iter 341 / 1327 | time 1526[s] | perplexity 140.56\n",
      "| epoch 4 |  iter 361 / 1327 | time 1533[s] | perplexity 181.57\n",
      "| epoch 4 |  iter 381 / 1327 | time 1541[s] | perplexity 136.67\n",
      "| epoch 4 |  iter 401 / 1327 | time 1549[s] | perplexity 152.57\n",
      "| epoch 4 |  iter 421 / 1327 | time 1556[s] | perplexity 135.11\n",
      "| epoch 4 |  iter 441 / 1327 | time 1563[s] | perplexity 147.36\n",
      "| epoch 4 |  iter 461 / 1327 | time 1570[s] | perplexity 140.04\n",
      "| epoch 4 |  iter 481 / 1327 | time 1577[s] | perplexity 140.89\n",
      "| epoch 4 |  iter 501 / 1327 | time 1584[s] | perplexity 150.52\n",
      "| epoch 4 |  iter 521 / 1327 | time 1592[s] | perplexity 161.92\n",
      "| epoch 4 |  iter 541 / 1327 | time 1599[s] | perplexity 153.51\n",
      "| epoch 4 |  iter 561 / 1327 | time 1606[s] | perplexity 141.16\n",
      "| epoch 4 |  iter 581 / 1327 | time 1613[s] | perplexity 123.46\n",
      "| epoch 4 |  iter 601 / 1327 | time 1620[s] | perplexity 173.66\n",
      "| epoch 4 |  iter 621 / 1327 | time 1627[s] | perplexity 166.07\n",
      "| epoch 4 |  iter 641 / 1327 | time 1634[s] | perplexity 153.55\n",
      "| epoch 4 |  iter 661 / 1327 | time 1641[s] | perplexity 145.06\n",
      "| epoch 4 |  iter 681 / 1327 | time 1648[s] | perplexity 115.55\n",
      "| epoch 4 |  iter 701 / 1327 | time 1655[s] | perplexity 137.76\n",
      "| epoch 4 |  iter 721 / 1327 | time 1662[s] | perplexity 147.55\n",
      "| epoch 4 |  iter 741 / 1327 | time 1670[s] | perplexity 129.66\n",
      "| epoch 4 |  iter 761 / 1327 | time 1677[s] | perplexity 125.22\n",
      "| epoch 4 |  iter 781 / 1327 | time 1684[s] | perplexity 121.77\n",
      "| epoch 4 |  iter 801 / 1327 | time 1691[s] | perplexity 136.02\n",
      "| epoch 4 |  iter 821 / 1327 | time 1698[s] | perplexity 135.07\n",
      "| epoch 4 |  iter 841 / 1327 | time 1705[s] | perplexity 134.73\n",
      "| epoch 4 |  iter 861 / 1327 | time 1712[s] | perplexity 141.62\n",
      "| epoch 4 |  iter 881 / 1327 | time 1719[s] | perplexity 123.82\n",
      "| epoch 4 |  iter 901 / 1327 | time 1726[s] | perplexity 156.90\n",
      "| epoch 4 |  iter 921 / 1327 | time 1733[s] | perplexity 139.46\n",
      "| epoch 4 |  iter 941 / 1327 | time 1740[s] | perplexity 151.50\n",
      "| epoch 4 |  iter 961 / 1327 | time 1747[s] | perplexity 152.57\n",
      "| epoch 4 |  iter 981 / 1327 | time 1754[s] | perplexity 143.37\n",
      "| epoch 4 |  iter 1001 / 1327 | time 1762[s] | perplexity 129.56\n",
      "| epoch 4 |  iter 1021 / 1327 | time 1769[s] | perplexity 148.69\n",
      "| epoch 4 |  iter 1041 / 1327 | time 1776[s] | perplexity 137.89\n",
      "| epoch 4 |  iter 1061 / 1327 | time 1783[s] | perplexity 121.04\n",
      "| epoch 4 |  iter 1081 / 1327 | time 1791[s] | perplexity 109.22\n",
      "| epoch 4 |  iter 1101 / 1327 | time 1798[s] | perplexity 113.17\n",
      "| epoch 4 |  iter 1121 / 1327 | time 1805[s] | perplexity 141.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 4 |  iter 1141 / 1327 | time 1812[s] | perplexity 134.92\n",
      "| epoch 4 |  iter 1161 / 1327 | time 1819[s] | perplexity 127.48\n",
      "| epoch 4 |  iter 1181 / 1327 | time 1826[s] | perplexity 127.70\n",
      "| epoch 4 |  iter 1201 / 1327 | time 1833[s] | perplexity 113.46\n",
      "| epoch 4 |  iter 1221 / 1327 | time 1840[s] | perplexity 101.33\n",
      "| epoch 4 |  iter 1241 / 1327 | time 1847[s] | perplexity 126.34\n",
      "| epoch 4 |  iter 1261 / 1327 | time 1854[s] | perplexity 124.97\n",
      "| epoch 4 |  iter 1281 / 1327 | time 1861[s] | perplexity 121.14\n",
      "| epoch 4 |  iter 1301 / 1327 | time 1869[s] | perplexity 149.47\n",
      "| epoch 4 |  iter 1321 / 1327 | time 1876[s] | perplexity 147.44\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating perplexity ...\n",
      "234 / 235\n",
      "test perplexity:  153.9599240830437\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータ\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 学習データの読み込み\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# モデルの生成\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 勾配クリッピングを適用して学習\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# テストデータで取得\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('test perplexity: ', ppl_test)\n",
    "\n",
    "# パラメータの保存\n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>RnnlmTrainer</code>クラスによる学習\n",
    "  - <code>fit()</code>メソッドでモデルの勾配を求め, モデルのパラメータを更新する\n",
    "  - 引数<code>max_grad</code>の指定によって勾配クリッピングが適用される\n",
    "  \n",
    "---\n",
    "\n",
    "## RNNLMのさらなる改善\n",
    "\n",
    "1. LSTMレイヤの多層化\n",
    "  - ここまでは1層のLSTMレイヤだが複数層重ねることで精度向上が期待できる\n",
    "  - 適切な層数に関してはハイパーパラメータであるため取り組む問題の難解さ等で異なってくる\n",
    "    - 参考までにPTBデータセットにおいては2~4程度が良い\n",
    "2. Dropoutによる過学習の抑制\n",
    "  - 画像認識等に用いられるようなCNN同様ランダムにニューロンを選び, そのニューロンを無視する\n",
    "  - 差し込むには時間軸方向ではなく深さ方向に行うべき\n",
    "    - 時間軸方向に差し込むと時間の進行と比例してDropoutによるノイズが蓄積するため\n",
    "3. 重み共有\n",
    "  - EmbeddingレイヤとAffineレイヤの重みを共有するテクニック\n",
    "    - 学習パラメータの削減と精度向上が期待できる\n",
    "    - 語彙数$V$, LSTMの隠れ状態の次元数を$H$とした時, Embedding, Affineのそれぞれのレイヤの重み形状は$(V \\times H), (H \\times V)$となる\n",
    "      - なのでEmbeddingレイヤの重みの転置をAffineレイヤに適用することで共有が可能となる\n",
    "\n",
    "\n",
    "- 上記の改善点を踏まえて実装を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650, hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4*H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4*H).astype('f')\n",
    "        lstm_Wx2 = (rn(D, 4*H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4*H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # 改善\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),  # Dropout層の追加\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),  # LSTMレイヤの追加\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b) # 重み共有\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "        \n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "    \n",
    "    def predict(self, xs, train_fig=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_fig = train_fig\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "    \n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "| epoch 1 |  iter 1 / 1327 | time 2[s] | perplexity 9999.71\n",
      "| epoch 1 |  iter 21 / 1327 | time 55[s] | perplexity 2332.97\n",
      "| epoch 1 |  iter 41 / 1327 | time 109[s] | perplexity 1302.56\n",
      "| epoch 1 |  iter 61 / 1327 | time 163[s] | perplexity 1101.87\n",
      "| epoch 1 |  iter 81 / 1327 | time 216[s] | perplexity 973.52\n",
      "| epoch 1 |  iter 101 / 1327 | time 269[s] | perplexity 884.20\n",
      "| epoch 1 |  iter 121 / 1327 | time 322[s] | perplexity 878.35\n",
      "| epoch 1 |  iter 141 / 1327 | time 376[s] | perplexity 860.45\n",
      "| epoch 1 |  iter 161 / 1327 | time 429[s] | perplexity 827.08\n",
      "| epoch 1 |  iter 181 / 1327 | time 483[s] | perplexity 871.50\n",
      "| epoch 1 |  iter 201 / 1327 | time 536[s] | perplexity 775.38\n",
      "| epoch 1 |  iter 221 / 1327 | time 589[s] | perplexity 803.86\n",
      "| epoch 1 |  iter 241 / 1327 | time 642[s] | perplexity 765.87\n",
      "| epoch 1 |  iter 261 / 1327 | time 695[s] | perplexity 809.67\n",
      "| epoch 1 |  iter 281 / 1327 | time 750[s] | perplexity 777.52\n",
      "| epoch 1 |  iter 301 / 1327 | time 803[s] | perplexity 727.44\n",
      "| epoch 1 |  iter 321 / 1327 | time 856[s] | perplexity 669.06\n",
      "| epoch 1 |  iter 341 / 1327 | time 909[s] | perplexity 840.53\n",
      "| epoch 1 |  iter 361 / 1327 | time 964[s] | perplexity 1123.16\n",
      "| epoch 1 |  iter 381 / 1327 | time 1017[s] | perplexity 808.68\n",
      "| epoch 1 |  iter 401 / 1327 | time 1071[s] | perplexity 782.32\n",
      "| epoch 1 |  iter 421 / 1327 | time 1124[s] | perplexity 802.63\n",
      "| epoch 1 |  iter 441 / 1327 | time 1177[s] | perplexity 781.69\n",
      "| epoch 1 |  iter 461 / 1327 | time 1231[s] | perplexity 784.08\n",
      "| epoch 1 |  iter 481 / 1327 | time 1285[s] | perplexity 733.68\n",
      "| epoch 1 |  iter 501 / 1327 | time 1338[s] | perplexity 719.24\n",
      "| epoch 1 |  iter 521 / 1327 | time 1391[s] | perplexity 718.34\n",
      "| epoch 1 |  iter 541 / 1327 | time 1444[s] | perplexity 759.95\n",
      "| epoch 1 |  iter 561 / 1327 | time 1498[s] | perplexity 702.00\n",
      "| epoch 1 |  iter 581 / 1327 | time 1553[s] | perplexity 654.56\n",
      "| epoch 1 |  iter 601 / 1327 | time 1608[s] | perplexity 770.69\n",
      "| epoch 1 |  iter 621 / 1327 | time 1661[s] | perplexity 713.36\n",
      "| epoch 1 |  iter 641 / 1327 | time 1716[s] | perplexity 642.28\n",
      "| epoch 1 |  iter 661 / 1327 | time 1770[s] | perplexity 624.85\n",
      "| epoch 1 |  iter 681 / 1327 | time 1824[s] | perplexity 567.91\n",
      "| epoch 1 |  iter 701 / 1327 | time 1878[s] | perplexity 584.22\n",
      "| epoch 1 |  iter 721 / 1327 | time 1934[s] | perplexity 571.28\n",
      "| epoch 1 |  iter 741 / 1327 | time 1991[s] | perplexity 496.95\n",
      "| epoch 1 |  iter 761 / 1327 | time 2048[s] | perplexity 534.02\n",
      "| epoch 1 |  iter 781 / 1327 | time 2104[s] | perplexity 494.89\n",
      "| epoch 1 |  iter 801 / 1327 | time 2160[s] | perplexity 518.11\n",
      "| epoch 1 |  iter 821 / 1327 | time 2217[s] | perplexity 503.90\n",
      "| epoch 1 |  iter 841 / 1327 | time 2273[s] | perplexity 489.99\n",
      "| epoch 1 |  iter 861 / 1327 | time 2328[s] | perplexity 486.43\n",
      "| epoch 1 |  iter 881 / 1327 | time 2387[s] | perplexity 454.03\n",
      "| epoch 1 |  iter 901 / 1327 | time 2446[s] | perplexity 495.11\n",
      "| epoch 1 |  iter 921 / 1327 | time 2503[s] | perplexity 460.38\n",
      "| epoch 1 |  iter 941 / 1327 | time 2559[s] | perplexity 458.34\n",
      "| epoch 1 |  iter 961 / 1327 | time 2614[s] | perplexity 483.11\n",
      "| epoch 1 |  iter 981 / 1327 | time 2670[s] | perplexity 449.50\n",
      "| epoch 1 |  iter 1001 / 1327 | time 2727[s] | perplexity 398.05\n",
      "| epoch 1 |  iter 1021 / 1327 | time 2781[s] | perplexity 446.66\n",
      "| epoch 1 |  iter 1041 / 1327 | time 2836[s] | perplexity 410.94\n",
      "| epoch 1 |  iter 1061 / 1327 | time 2892[s] | perplexity 396.81\n",
      "| epoch 1 |  iter 1081 / 1327 | time 2947[s] | perplexity 361.00\n",
      "| epoch 1 |  iter 1101 / 1327 | time 3003[s] | perplexity 388.38\n",
      "| epoch 1 |  iter 1121 / 1327 | time 3058[s] | perplexity 425.53\n",
      "| epoch 1 |  iter 1141 / 1327 | time 3114[s] | perplexity 401.17\n",
      "| epoch 1 |  iter 1161 / 1327 | time 3171[s] | perplexity 383.71\n",
      "| epoch 1 |  iter 1181 / 1327 | time 3226[s] | perplexity 362.14\n",
      "| epoch 1 |  iter 1201 / 1327 | time 3282[s] | perplexity 314.11\n",
      "| epoch 1 |  iter 1221 / 1327 | time 3337[s] | perplexity 315.02\n",
      "| epoch 1 |  iter 1241 / 1327 | time 3392[s] | perplexity 366.88\n",
      "| epoch 1 |  iter 1261 / 1327 | time 3447[s] | perplexity 323.42\n",
      "| epoch 1 |  iter 1281 / 1327 | time 3503[s] | perplexity 346.01\n",
      "| epoch 1 |  iter 1301 / 1327 | time 3559[s] | perplexity 407.97\n",
      "| epoch 1 |  iter 1321 / 1327 | time 3614[s] | perplexity 363.13\n",
      "evaluating perplexity ...\n",
      "209 / 210\n",
      "valid perplexity:  353.13174137442167\n",
      "--------------------------------------------------\n",
      "| epoch 2 |  iter 1 / 1327 | time 2[s] | perplexity 455.94\n",
      "| epoch 2 |  iter 21 / 1327 | time 61[s] | perplexity 373.30\n",
      "| epoch 2 |  iter 41 / 1327 | time 118[s] | perplexity 352.30\n",
      "| epoch 2 |  iter 61 / 1327 | time 175[s] | perplexity 323.57\n",
      "| epoch 2 |  iter 81 / 1327 | time 234[s] | perplexity 308.61\n",
      "| epoch 2 |  iter 101 / 1327 | time 292[s] | perplexity 284.55\n",
      "| epoch 2 |  iter 121 / 1327 | time 350[s] | perplexity 304.27\n",
      "| epoch 2 |  iter 141 / 1327 | time 408[s] | perplexity 324.09\n",
      "| epoch 2 |  iter 161 / 1327 | time 465[s] | perplexity 347.81\n",
      "| epoch 2 |  iter 181 / 1327 | time 522[s] | perplexity 359.53\n",
      "| epoch 2 |  iter 201 / 1327 | time 578[s] | perplexity 328.18\n",
      "| epoch 2 |  iter 221 / 1327 | time 634[s] | perplexity 330.64\n",
      "| epoch 2 |  iter 241 / 1327 | time 689[s] | perplexity 308.12\n",
      "| epoch 2 |  iter 261 / 1327 | time 745[s] | perplexity 331.62\n",
      "| epoch 2 |  iter 281 / 1327 | time 801[s] | perplexity 337.25\n",
      "| epoch 2 |  iter 301 / 1327 | time 857[s] | perplexity 302.46\n",
      "| epoch 2 |  iter 321 / 1327 | time 913[s] | perplexity 263.02\n",
      "| epoch 2 |  iter 341 / 1327 | time 969[s] | perplexity 328.82\n",
      "| epoch 2 |  iter 361 / 1327 | time 1025[s] | perplexity 346.82\n",
      "| epoch 2 |  iter 381 / 1327 | time 1080[s] | perplexity 288.91\n",
      "| epoch 2 |  iter 401 / 1327 | time 1136[s] | perplexity 322.91\n",
      "| epoch 2 |  iter 421 / 1327 | time 1192[s] | perplexity 309.21\n",
      "| epoch 2 |  iter 441 / 1327 | time 1247[s] | perplexity 302.77\n",
      "| epoch 2 |  iter 461 / 1327 | time 1303[s] | perplexity 304.90\n",
      "| epoch 2 |  iter 481 / 1327 | time 1360[s] | perplexity 287.70\n",
      "| epoch 2 |  iter 501 / 1327 | time 1417[s] | perplexity 309.46\n",
      "| epoch 2 |  iter 521 / 1327 | time 1473[s] | perplexity 296.41\n",
      "| epoch 2 |  iter 541 / 1327 | time 1529[s] | perplexity 320.31\n",
      "| epoch 2 |  iter 561 / 1327 | time 1585[s] | perplexity 285.97\n",
      "| epoch 2 |  iter 581 / 1327 | time 1642[s] | perplexity 268.95\n",
      "| epoch 2 |  iter 601 / 1327 | time 1697[s] | perplexity 344.64\n",
      "| epoch 2 |  iter 621 / 1327 | time 1753[s] | perplexity 318.75\n",
      "| epoch 2 |  iter 641 / 1327 | time 1809[s] | perplexity 299.24\n",
      "| epoch 2 |  iter 661 / 1327 | time 1864[s] | perplexity 283.93\n",
      "| epoch 2 |  iter 681 / 1327 | time 1920[s] | perplexity 248.41\n",
      "| epoch 2 |  iter 701 / 1327 | time 1974[s] | perplexity 271.16\n",
      "| epoch 2 |  iter 721 / 1327 | time 2029[s] | perplexity 283.81\n",
      "| epoch 2 |  iter 741 / 1327 | time 2084[s] | perplexity 241.08\n",
      "| epoch 2 |  iter 761 / 1327 | time 2138[s] | perplexity 257.85\n",
      "| epoch 2 |  iter 781 / 1327 | time 2193[s] | perplexity 245.92\n",
      "| epoch 2 |  iter 801 / 1327 | time 2249[s] | perplexity 271.94\n",
      "| epoch 2 |  iter 821 / 1327 | time 2305[s] | perplexity 255.96\n",
      "| epoch 2 |  iter 841 / 1327 | time 2361[s] | perplexity 260.55\n",
      "| epoch 2 |  iter 861 / 1327 | time 2417[s] | perplexity 256.07\n",
      "| epoch 2 |  iter 881 / 1327 | time 2473[s] | perplexity 238.78\n",
      "| epoch 2 |  iter 901 / 1327 | time 2529[s] | perplexity 295.58\n",
      "| epoch 2 |  iter 921 / 1327 | time 2584[s] | perplexity 265.79\n",
      "| epoch 2 |  iter 941 / 1327 | time 2643[s] | perplexity 274.89\n",
      "| epoch 2 |  iter 961 / 1327 | time 2700[s] | perplexity 284.06\n",
      "| epoch 2 |  iter 981 / 1327 | time 2755[s] | perplexity 269.22\n",
      "| epoch 2 |  iter 1001 / 1327 | time 2813[s] | perplexity 232.52\n",
      "| epoch 2 |  iter 1021 / 1327 | time 2870[s] | perplexity 268.22\n",
      "| epoch 2 |  iter 1041 / 1327 | time 2927[s] | perplexity 250.96\n",
      "| epoch 2 |  iter 1061 / 1327 | time 2983[s] | perplexity 240.72\n",
      "| epoch 2 |  iter 1081 / 1327 | time 3037[s] | perplexity 210.13\n",
      "| epoch 2 |  iter 1101 / 1327 | time 3090[s] | perplexity 240.28\n",
      "| epoch 2 |  iter 1121 / 1327 | time 3144[s] | perplexity 276.58\n",
      "| epoch 2 |  iter 1141 / 1327 | time 3198[s] | perplexity 255.88\n",
      "| epoch 2 |  iter 1161 / 1327 | time 3251[s] | perplexity 246.89\n"
     ]
    }
   ],
   "source": [
    "from common import config\n",
    "# GPUで実行しない場合は下記をコメントアウト\n",
    "# GPUを使わない場合後に出てくるBetterRnnlm()の学習に2日要す\n",
    "config.GPU = True\n",
    "\n",
    "# ハイパーパラメータ\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 学習データの読み込み\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "print('start')\n",
    "# モデルの生成\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size, time_size=time_size, max_grad=max_grad)\n",
    "    \n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('valid perplexity: ', ppl)\n",
    "    \n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "        \n",
    "    model.reset_state()\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "# テストデータでの評価\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('test perplexity: ', ppl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('DL-from-Scratch2': venv)",
   "language": "python",
   "name": "python37364bitdlfromscratch2venvf2e9687bc0124088b33a9bcbeb1d9a2b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
